{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thoechsmann/automatic1111-collab/blob/main/automatic1111_ipynb_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6OFCYOzNjDX"
      },
      "source": [
        "# [Stable Diffusion WebUI Colab](https://github.com/ddPn08/stable-diffusion-webui-colab) by [ddPn08](https://github.com/ddpn08/)\n",
        "\n",
        "## Wiki\n",
        "https://github.com/ddPn08/automatic1111-colab/wiki\n",
        "\n",
        "<br />\n",
        "\n",
        "# Troubleshooting (不具合が発生したら)\n",
        "1. First, check the wiki and changelog. (まずは、Wikiと変更ログを確認してください。)\n",
        "  - [Wiki](https://github.com/ddPn08/automatic1111-colab/wiki)\n",
        "  - [CHANGELOG | 変更ログ](#scrollTo=moDR3lrJVsE8)\n",
        "\n",
        "2. If you still can't figure it out, open a Github issue. (それでもわからない場合はGithubのIssueを立ててください。)\n",
        "  - [Github Issue](https://github.com/ddPn08/automatic1111-colab/issues/new)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4xxtQfuJiWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37425284-e6e6-40ca-dfb7-af1a4f37b606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 14 13:24:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:           83Gi       945Mi        79Gi       1.0Mi       3.4Gi        81Gi\n",
            "Swap:            0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi\n",
        "! nvcc -V\n",
        "! free -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE45Pqn_N81E"
      },
      "source": [
        "## 1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXkcQu6OEAu"
      },
      "source": [
        "### 1.1 Clone repository\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-EN#11-clone-repository) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-JP#11-リポジトリのクローン)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzdbQDudNZ6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b913763-14f3-4d54-dc9c-d8b716e713ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 17106, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 17106 (delta 0), reused 1 (delta 0), pack-reused 17105\u001b[K\n",
            "Receiving objects: 100% (17106/17106), 27.84 MiB | 8.98 MiB/s, done.\n",
            "Resolving deltas: 100% (11953/11953), done.\n",
            "/content/stable-diffusion-webui\n",
            "Already on 'master'\n",
            "Your branch is up to date with 'origin/master'.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "repository_url = \"https://github.com/AUTOMATIC1111/stable-diffusion-webui\"  # @param {type: \"string\"}\n",
        "webui_branch = \"master\"  # @param {type: \"string\"}\n",
        "\n",
        "! git clone {repository_url}\n",
        "%cd /content/stable-diffusion-webui\n",
        "! git checkout {webui_branch}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHgDng2c0FX"
      },
      "source": [
        "### 1.2 Setup models\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-EN#12-setup-models) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-JP#12-モデルのセットアップ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "Mls4_48XOrTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0471cfc4-112c-4b96-a9ca-71eab1d5e3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Getting config: Downloading https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1873  100  1873    0     0  81434      0 --:--:-- --:--:-- --:--:-- 81434\n",
            "Getting config: Downloading https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1789  100  1789    0     0   5590      0 --:--:-- --:--:-- --:--:--  5590\n",
            "Getting config: Downloading https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inpainting-inference.yaml\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4450  100  4450    0     0  12606      0 --:--:-- --:--:-- --:--:-- 12606\n",
            "Getting config: Downloading https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1815  100  1815    0     0   3637      0 --:--:-- --:--:-- --:--:--  3637\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Set up the StableDiffusion model.\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "data_dir = \"/content/drive/Shareddrives/AI/Thomas/sd_collab2\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Optional | Download the model if it isn't already in the `{data_dir}/models` folder**\n",
        "\n",
        "# @markdown Get huggingface access token from [here](https://huggingface.co/settings/tokens)\n",
        "auth_token = \"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\"  # @param {type:\"string\"}\n",
        "\n",
        "download_if_missing = True  # @param {type:\"boolean\"}\n",
        "# @markdown If you use the SD 2.1 model, select its config from the dropdown\n",
        "\n",
        "# @markdown model_url2, 3, config_url2, 3, vae_url2, 3 are option. <br>\n",
        "# @markdown If you have models, config or vae that you want to load at the same time, please enter them.\n",
        "model_url = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\" #@param [\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float16.ckpt\", \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.ckpt\", \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\"] {allow-input: true}\n",
        "config_url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "\n",
        "model_url2 = \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\" #@param [\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float16.ckpt\", \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.ckpt\", \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\"] {allow-input: true}\n",
        "config_url2 = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "\n",
        "model_url3 = \"https://huggingface.co/stabilityai/stable-diffusion-2-inpainting/resolve/main/512-inpainting-ema.ckpt\" #@param [\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float16.ckpt\", \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.ckpt\", \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\"] {allow-input: true}\n",
        "config_url3 = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inpainting-inference.yaml\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "\n",
        "model_url4 = \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.ckpt\" #@param [\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float16.ckpt\", \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.ckpt\", \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\"] {allow-input: true}\n",
        "config_url4 = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "\n",
        "# config_url5 = \"https://github.com/Stability-AI/stablediffusion/blob/main/configs/stable-diffusion/x4-upscaling.yaml\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "# config_url6 = \"https://github.com/Stability-AI/stablediffusion/blob/main/configs/stable-diffusion/v2-midas-inference.yaml\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "\n",
        "use_vae = False # @param {type:\"boolean\"}\n",
        "vae_url = \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.vae.pt\" #@param [\"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.vae.pt\",\"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/anything-v4.0.vae.pt\"] {allow-input: true}\n",
        "vae_url2 = \"\" #@param [\"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.vae.pt\",\"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/anything-v4.0.vae.pt\"] {allow-input: true}\n",
        "vae_url3 = \"\" #@param [\"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.vae.pt\",\"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/anything-v4.0.vae.pt\"] {allow-input: true}\n",
        "\n",
        "model_urls = [model_url, model_url2, model_url3, model_url4]\n",
        "config_urls = [config_url, config_url2, config_url3, config_url4]\n",
        "vae_urls = [vae_url, vae_url2, vae_url3]\n",
        "\n",
        "# @markdown **Optional | Use Google Drive**\n",
        "mount_google_drive = True  # @param {type:\"boolean\"}\n",
        "# @markdown If you load multiple models/config/vae, it is recommended to check force_model_download_locally\n",
        "force_model_download_locally = False  # @param {type:\"boolean\"}\n",
        "force_remount = False  # @param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "mount_success = False\n",
        "drive_path = \"/content/drive\"\n",
        "if mount_google_drive and not os.path.exists(drive_path):\n",
        "    from google.colab import drive\n",
        "\n",
        "    try:\n",
        "        drive.mount(drive_path, force_remount=force_remount)\n",
        "        data_dir_gdrive = \"/content/drive/MyDrive/AI/automatic1111\"  # @param {type:\"string\"}\n",
        "        os.makedirs(data_dir_gdrive, exist_ok=True)\n",
        "        ! rm -Rf {data_dir} && ln -s {data_dir_gdrive} {data_dir}\n",
        "        mount_success = True\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/script.pre.sh\"):\n",
        "    ! chmod +x {data_dir}/script.pre.sh\n",
        "    ! {data_dir}/script.pre.sh\n",
        "\n",
        "models_path = f\"{data_dir}/models\"\n",
        "output_path = f\"{data_dir}/outputs\"\n",
        "config_path = f\"{data_dir}/config\"\n",
        "scripts_path = f\"{data_dir}/scripts\"\n",
        "extensions_file_path = f\"{data_dir}/extensions.txt\"\n",
        "\n",
        "if force_model_download_locally:\n",
        "    models_path = \"/content/models\"\n",
        "\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "os.makedirs(config_path, exist_ok=True)\n",
        "os.makedirs(scripts_path, exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/Stable-diffusion\", exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/VAE\", exist_ok=True)\n",
        "\n",
        "for script in os.listdir(scripts_path):\n",
        "    ! rm -Rf stable-diffusion-webui/scripts/{script} && ln -s {scripts_path}/{script} stable-diffusion-webui/scripts/{script}\n",
        "\n",
        "for dir in os.listdir(models_path):\n",
        "    if dir == \"embeddings\":\n",
        "        ! rm -Rf stable-diffusion-webui/embeddings && ln -s {models_path}/embeddings stable-diffusion-webui/embeddings\n",
        "    else:\n",
        "        ! rm -Rf stable-diffusion-webui/models/{dir} && ln -s {models_path}/{dir} stable-diffusion-webui/models/{dir}\n",
        "\n",
        "! rm -Rf stable-diffusion-webui/outputs && ln -s {data_dir}/outputs stable-diffusion-webui/outputs\n",
        "\n",
        "for filename in [\"config.json\", \"ui-config.json\", \"styles.csv\", \"artists.csv\"]:\n",
        "    ! rm -f stable-diffusion-webui/{filename}\n",
        "    filepath = f\"{config_path}/{filename}\"\n",
        "    if not os.path.exists(filepath):\n",
        "        if filename.endswith(\".json\"):\n",
        "            with open(filepath, mode=\"w\") as f:\n",
        "                f.write(\"{}\")\n",
        "        else:\n",
        "            ! touch {config_path}/{filename}\n",
        "    ! ln -s {config_path}/{filename} stable-diffusion-webui/{filename}\n",
        "\n",
        "if download_if_missing:\n",
        "    pos = 0\n",
        "    for url in model_urls:\n",
        "        filename = url.split(\"/\")[-1]\n",
        "        if not os.path.exists(f\"{models_path}/Stable-diffusion/{filename}\"):\n",
        "            ! curl -LJ {url} -o {models_path}/Stable-diffusion/{filename} {'-H \"Authorization: Bearer ' + auth_token + '\"' if auth_token else \"\"}\n",
        "\n",
        "        # get config\n",
        "        config_url = config_urls[pos]\n",
        "        print(f\"Getting config: Downloading {config_url}\")\n",
        "        prefix_model = filename.split(\".\")[0]\n",
        "        ! curl -LJ {config_url} -o {models_path}/Stable-diffusion/{prefix_model}.yaml \n",
        "        pos += 1\n",
        "\n",
        "\n",
        "    if use_vae:\n",
        "      for vae_url in vae_urls:\n",
        "        vae_filename = vae_url.split(\"/\")[-1]\n",
        "        if not os.path.exists(f\"{models_path}/VAE/{vae_filename}\"):\n",
        "            ! curl -LJ {vae_url} -o {models_path}/VAE/{vae_filename} {'-H \"Authorization: Bearer ' + auth_token + '\"' if auth_token else \"\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JkrcrPBza-M"
      },
      "source": [
        "## 2 - Advanced - Launch preferences\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/2.-Launch-preferences-%7C-EN#2-launch-preferences) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/2.-Launch-preferences-%7C-JP#2-起動設定)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goUvyTZ4zd4l"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Command line arguments\n",
        "\n",
        "import os\n",
        "\n",
        "no_half = False  # @param {type:\"boolean\"}\n",
        "no_half_vae = True  # @param {type:\"boolean\"}\n",
        "allow_code = False  # @param {type:\"boolean\"}\n",
        "no_progressbar_hiding = False  # @param {type:\"boolean\"}\n",
        "medvram = False  # @param {type:\"boolean\"}\n",
        "lowvram = False  # @param {type:\"boolean\"}\n",
        "deepdanbooru = False  # @param {type:\"boolean\"}\n",
        "xformers = True  # @param {type:\"boolean\"}\n",
        "disable_opt_split_attention = False  # @param {type:\"boolean\"}\n",
        "gradio_queue = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown  <br >\n",
        "custom_arguments = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "run_string_with_variables = {\n",
        "    \"--no-half\": f\"{no_half}\",\n",
        "    \"--no-half-vae\": f\"{no_half_vae}\",\n",
        "    \"--allow-code\": f\"{allow_code}\",\n",
        "    \"--no-progressbar-hiding\": f\"{no_progressbar_hiding}\",\n",
        "    \"--medvram\": f\"{medvram}\",\n",
        "    \"--lowvram\": f\"{lowvram}\",\n",
        "    \"--deepdanbooru\": f\"{deepdanbooru}\",\n",
        "    \"--xformers\": f\"{xformers}\",\n",
        "    \"--disable-opt-split-attention\": f\"{disable_opt_split_attention}\",\n",
        "}\n",
        "if use_vae:\n",
        "      for vae_url in vae_urls:\n",
        "        vae_filename = vae_url.split(\"/\")[-1]\n",
        "        if os.path.exists(f\"{models_path}/VAE/{vae_filename}\") and vae_filename:\n",
        "           key = \"--vae-path /content/stable-diffusion-webui/models/VAE/\" + vae_filename\n",
        "           run_string_with_variables[key] = f\"{use_vae}\"\n",
        "\n",
        "\n",
        "advanced_options = {k for (k, v) in run_string_with_variables.items() if v == \"True\"}\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Enable password authentication (Prevent other users from using the WebUI)\n",
        "\n",
        "# @markdown  <br >\n",
        "\n",
        "use_gradio_auth = False  # @param {type:\"boolean\"}\n",
        "gradio_auth_username = \"username\"  # @param {type:\"string\"}\n",
        "gradio_auth_password = \"password\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown # Advanced | Network preferences\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Optional | Ngrok Tunnel\n",
        "# @markdown Get token from [here](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "use_ngrok = False  # @param {type: \"boolean\"}\n",
        "load_token_from_gdrive = True  # @param {type:\"boolean\"}\n",
        "ngrok_auth_token = \"\"  # @param {type: \"string\"}\n",
        "ngrok_region = \"default\"  # @param [\"default\", \"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/ngrok.txt\") and use_ngrok:\n",
        "    with open(f\"{data_dir}/ngrok.txt\", mode=\"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        if not ngrok_auth_token and len(lines) > 0:\n",
        "            ngrok_auth_token = lines[0].strip()\n",
        "        if ngrok_region == \"default\" and len(lines) > 1:\n",
        "            ngrok_region = lines[1].strip()\n",
        "\n",
        "with open(f\"{data_dir}/ngrok.txt\", mode=\"w\") as f:\n",
        "    f.write(f\"{ngrok_auth_token}\\n{ngrok_region}\")\n",
        "\n",
        "if not ngrok_region or ngrok_region == \"default\":\n",
        "    ngrok_region = \"us\"\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Extensions\n",
        "load_extensions_from_gdrive = True  # @param {type:\"boolean\"}\n",
        "extensions = \"https://github.com/yfszzx/stable-diffusion-webui-images-browser, https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\"  # @param {type:\"string\"}\n",
        "extensions = list(map(str.strip, extensions.split(\",\")))\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Save extensions to Google Drive\n",
        "# @markdown **Deprecated** (Unexpected errors may occur)\n",
        "save_extensions_to_gdrive = False  # @param {type:\"boolean\"}\n",
        "\n",
        "if save_extensions_to_gdrive:\n",
        "    os.makedirs(f\"{data_dir}/extensions\", exist_ok=True)\n",
        "    ! rm -Rf stable-diffusion-webui/extensions && ln -s {data_dir}/extensions stable-diffusion-webui/extensions\n",
        "\n",
        "if load_extensions_from_gdrive and extensions_file_path:\n",
        "    if os.path.exists(extensions_file_path):\n",
        "        with open(extensions_file_path, mode=\"r\") as f:\n",
        "            for s in f:\n",
        "                url = s.strip()\n",
        "                if url not in extensions:\n",
        "                    extensions.append(url)\n",
        "    with open(extensions_file_path, mode=\"w+\") as f:\n",
        "        f.write(\"\\n\".join(extensions))\n",
        "\n",
        "share_args = f\" --share {'--gradio-queue' if gradio_queue else ''}\"\n",
        "\n",
        "vars = \" \".join(advanced_options)\n",
        "if not use_ngrok:\n",
        "    vars += share_args\n",
        "elif ngrok_auth_token and ngrok_region:\n",
        "    vars += f\" --ngrok {ngrok_auth_token} --ngrok-region {ngrok_region}\"\n",
        "elif not ngrok_auth_token or not ngrok_region:\n",
        "    vars += share_args\n",
        "\n",
        "if use_gradio_auth:\n",
        "    vars += f\" --gradio-auth {gradio_auth_username}:{gradio_auth_password}\"\n",
        "\n",
        "os.environ[\"COMMANDLINE_ARGS\"] = f\"{vars} {custom_arguments}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htQtwGXHTaob"
      },
      "source": [
        "## 3 - Launch WebUI\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/3.-Run-%7C-EN#set-up-the-environment) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/3.-Run-%7C-JP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao2t5h5qG9HD",
        "outputId": "81f66b27-9cd9-430b-d564-d9b5ffb4bbcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui/extensions\n",
            "fatal: destination path 'stable-diffusion-webui-images-browser' already exists and is not an empty directory.\n",
            "fatal: destination path 'a1111-sd-webui-tagcomplete' already exists and is not an empty directory.\n",
            "/content\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorrt in /opt/conda/lib/python3.10/site-packages (8.5.3.1)\n",
            "Requirement already satisfied: triton in /opt/conda/lib/python3.10/site-packages (2.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11 in /opt/conda/lib/python3.10/site-packages (from tensorrt) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cublas-cu11 in /opt/conda/lib/python3.10/site-packages (from tensorrt) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11 in /opt/conda/lib/python3.10/site-packages (from tensorrt) (8.5.0.96)\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from triton) (1.13.1+cu117)\n",
            "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton) (15.0.7)\n",
            "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton) (3.25.2)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton) (3.9.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11->tensorrt) (65.6.3)\n",
            "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11->tensorrt) (0.37.1)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->triton) (4.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mPython 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]\n",
            "Commit hash: a9fed7c364061ae6efb37f797b6b522cb3cf7aa2\n",
            "Installing requirements for Web UI\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi==0.90.1\n",
            "  Using cached fastapi-0.90.1-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.90.1) (1.10.6)\n",
            "Collecting starlette<0.24.0,>=0.22.0\n",
            "  Using cached starlette-0.23.1-py3-none-any.whl (64 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.90.1) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.24.0,>=0.22.0->fastapi==0.90.1) (3.6.2)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.24.0,>=0.22.0->fastapi==0.90.1) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.24.0,>=0.22.0->fastapi==0.90.1) (1.3.0)\n",
            "Installing collected packages: starlette, fastapi\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.26.1\n",
            "    Uninstalling starlette-0.26.1:\n",
            "      Successfully uninstalled starlette-0.26.1\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.94.0\n",
            "    Uninstalling fastapi-0.94.0:\n",
            "      Successfully uninstalled fastapi-0.94.0\n",
            "Successfully installed fastapi-0.90.1 starlette-0.23.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @markdown ## Setup environment\n",
        "# @markdown This may take up to 5 minutes\n",
        "\n",
        "\n",
        "%cd /content/stable-diffusion-webui/extensions\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "for extension in extensions:\n",
        "    if extension.startswith(\"#\"):\n",
        "        continue\n",
        "    ! git clone {extension}\n",
        "    extension_name, _ = os.path.splitext(extension.split(\"/\")[-1])\n",
        "    if not os.path.isdir(extension_name):\n",
        "      ! git clone {extension}\n",
        "    else:\n",
        "      ! cd {extension_name} && git fetch\n",
        "\n",
        "%cd /content\n",
        "\n",
        "conda_dir = \"/opt/conda\"  # @param{type:\"string\"}\n",
        "conda_bin = os.path.join(conda_dir, \"bin\", \"conda\")\n",
        "\n",
        "if not os.path.exists(conda_bin):\n",
        "    ! curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p {conda_dir}\n",
        "    ! rm Miniconda3-latest-Linux-x86_64.sh\n",
        "\n",
        "\n",
        "install_script = f\"\"\"\n",
        "eval \"$({conda_bin} shell.bash hook)\"\n",
        "cd stable-diffusion-webui\n",
        "python3 -m pip install --upgrade tensorrt triton\n",
        "python -c 'from launch import prepare_environment; prepare_environment()'\n",
        "pip install --upgrade fastapi==0.90.1\n",
        "\"\"\"\n",
        "\n",
        "! {install_script}\n",
        "\n",
        "# @markdown  \n",
        "# @markdown ## Optional | Apply low RAM patch\n",
        "apply_lowram_patch = False  # @param {type: \"boolean\"}\n",
        "\n",
        "if apply_lowram_patch:\n",
        "    patches_dir = \"/content/patches\"\n",
        "    os.makedirs(patches_dir, exist_ok=True)\n",
        "    ! cd {patches_dir} && curl -LO https://raw.githubusercontent.com/ddPn08/automatic1111-colab/main/patches/stablediffusion-lowram.patch\n",
        "    ! cd /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai && git apply {patches_dir}/stablediffusion-lowram.patch\n",
        "\n",
        "\n",
        "os.environ[\n",
        "    \"LD_LIBRARY_PATH\"\n",
        "] = f\"{os.environ['LD_LIBRARY_PATH']}:/usr/local/envs/automatic/lib\"\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/script.post.sh\"):\n",
        "    ! chmod +x {data_dir}/script.post.sh\n",
        "    ! {data_dir}/script.post.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y4ebYsPqTrGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63793bcb-77f7-4790-9024-1e739b065932"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/stable-diffusion-webui\n",
            "Already up to date.\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "Python 3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]\n",
            "Commit hash: a9fed7c364061ae6efb37f797b6b522cb3cf7aa2\n",
            "Installing requirements for Web UI\n",
            "Launching Web UI with arguments: --xformers --no-half-vae --share --gradio-queue\n",
            "Loading weights [cc6cb27103] from /content/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.ckpt\n",
            "Creating model from config: /content/stable-diffusion-webui/models/Stable-diffusion/v1-5-pruned-emaonly.yaml\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:01<00:00, 869kB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 586kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 313kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 729kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 3.49MB/s]\n",
            "Applying xformers cross attention optimization.\n",
            "Textual inversion embeddings loaded(0): \n",
            "Model loaded in 20.8s (load weights from disk: 3.9s, create model: 12.0s, apply weights to model: 1.9s, apply half(): 1.1s, load VAE: 1.2s, move model to device: 0.6s).\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d701b5cb-6a34-4151.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "Startup time: 29.2s (import gradio: 1.9s, import ldm: 0.7s, other imports: 2.3s, list SD models: 0.4s, load scripts: 0.4s, load SD checkpoint: 20.9s, create ui: 0.4s, gradio launch: 2.1s).\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Run script\n",
        "# @markdown keep in mind that this script is set to run for ever.\n",
        "# @markdown > ※注意 このスクリプトは永久に実行されます。\n",
        "\n",
        "# @markdown  \n",
        "\n",
        "# @markdown ### Important - click the public URL to launch WebUI in another tab\n",
        "# @markdown > ### 重要 - 公開URLをクリックしてWebUIを起動してください\n",
        "\n",
        "# @markdown ![](https://user-images.githubusercontent.com/71378929/189563599-6df78bcf-133b-41e8-a55d-8ca3783cd933.png)\n",
        "\n",
        "%cd /content/stable-diffusion-webui/\n",
        "! git pull\n",
        "\n",
        "run_script = f\"\"\"\n",
        "eval \"$({conda_bin} shell.bash hook)\"\n",
        "accelerate launch --num_cpu_threads_per_process 1 launch.py\n",
        "\"\"\"\n",
        "! {run_script}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moDR3lrJVsE8"
      },
      "source": [
        "# CHANGELOG (変更ログ)\n",
        "\n",
        "## 2022/12/18 BREAKING CHANGE\n",
        "モデル等のディレクトリの構造を変更しました。くわしくは[こちら](https://github.com/ddPn08/automatic1111-colab/wiki/Data-directory-%7C-JP)  \n",
        "Changed the directory structure of models etc. For details [here](https://github.com/ddPn08/automatic1111-colab/wiki/Data-directory-%7C-EN)  \n",
        "\n",
        "## 2023/01/28\n",
        "- Simplified Python environment setup. / Python環境のセットアップをより簡潔にしました。\n",
        "- Removed Tailscale option. / Tailscaleオプションを削除しました。\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "automatic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "27f3fb6862b547830c34fbd0390b87507e21782526fd5ca25cfe7dc4f2b0fdae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}